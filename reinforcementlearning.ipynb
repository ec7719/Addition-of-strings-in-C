{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO98mLbdPm6Z1J5s3UP5qlE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ec7719/Addition-of-strings-in-C/blob/main/reinforcementlearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gym\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIu7GDsTBkHm",
        "outputId": "29697646-d8a2-4e5e-eae4-b404a7346e67"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import time\n",
        "\n",
        "class StickmanEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(StickmanEnv, self).__init__()\n",
        "\n",
        "        self.action_space = gym.spaces.Discrete(2)  # 2 actions: move left or move right\n",
        "        self.observation_space = gym.spaces.Discrete(5)  # 5 states: 0, 1, 2, 3, 4\n",
        "\n",
        "        self.stickman_position = 2\n",
        "    def render(self):\n",
        "        stickman_str = ''.join(['X' if i == self.stickman_position else '-' for i in range(5)])\n",
        "        print(stickman_str)\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    def reset(self):\n",
        "        self.stickman_position = 2\n",
        "        return self.stickman_position\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        if action == 0:\n",
        "            self.stickman_position = max(0, self.stickman_position - 1)\n",
        "        else:\n",
        "            self.stickman_position = min(4, self.stickman_position + 1)\n",
        "\n",
        "        if self.stickman_position == 0:\n",
        "            reward = -1\n",
        "            done = True\n",
        "        elif self.stickman_position == 4:\n",
        "            reward = 1\n",
        "            done = True\n",
        "        else:\n",
        "            reward = 0\n",
        "            done = False\n",
        "\n",
        "        return self.stickman_position, reward, done, {}\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, action_space_size, state_space_size, learning_rate=0.1, discount_factor=0.9, exploration_prob=0.2):\n",
        "        self.action_space_size = action_space_size\n",
        "        self.state_space_size = state_space_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.discount_factor = discount_factor\n",
        "        self.exploration_prob = exploration_prob\n",
        "\n",
        "        self.q_values = np.zeros((state_space_size, action_space_size))\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.rand() < self.exploration_prob:\n",
        "            return np.random.choice(self.action_space_size)\n",
        "        else:\n",
        "            return np.argmax(self.q_values[state, :])\n",
        "\n",
        "    def update_q_values(self, state, action, reward, next_state, done):\n",
        "        target = reward + self.discount_factor * np.max(self.q_values[next_state, :])\n",
        "        self.q_values[state, action] += self.learning_rate * (target - self.q_values[state, action])\n",
        "\n",
        "env = StickmanEnv()\n",
        "agent = QLearningAgent(action_space_size=2, state_space_size=5)\n",
        "\n",
        "num_episodes = 1000\n",
        "for episode in range(num_episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = agent.choose_action(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        agent.update_q_values(state, action, reward, next_state, done)\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "test_episodes = 10\n",
        "for episode in range(test_episodes):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = agent.choose_action(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "        env.render()\n",
        "\n",
        "    print(f\"Episode {episode + 1}: Stickman reached the goal with a reward of {reward}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKna1mzLBkb1",
        "outputId": "bde9dc8a-3be0-4624-b3c8-154f014824cb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---X-\n",
            "----X\n",
            "Episode 1: Stickman reached the goal with a reward of 1\n",
            "---X-\n",
            "----X\n",
            "Episode 2: Stickman reached the goal with a reward of 1\n",
            "---X-\n",
            "----X\n",
            "Episode 3: Stickman reached the goal with a reward of 1\n",
            "---X-\n",
            "----X\n",
            "Episode 4: Stickman reached the goal with a reward of 1\n",
            "---X-\n",
            "----X\n",
            "Episode 5: Stickman reached the goal with a reward of 1\n",
            "---X-\n",
            "----X\n",
            "Episode 6: Stickman reached the goal with a reward of 1\n",
            "---X-\n",
            "----X\n",
            "Episode 7: Stickman reached the goal with a reward of 1\n",
            "---X-\n",
            "----X\n",
            "Episode 8: Stickman reached the goal with a reward of 1\n",
            "---X-\n",
            "----X\n",
            "Episode 9: Stickman reached the goal with a reward of 1\n",
            "---X-\n",
            "----X\n",
            "Episode 10: Stickman reached the goal with a reward of 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cNGhCA53Btbr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}